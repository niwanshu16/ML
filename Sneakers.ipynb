{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sneakers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niwanshu16/ML/blob/master/Sneakers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZL6ehOp2mVm",
        "colab_type": "code",
        "outputId": "4a87093e-9fc7-404c-bfe4-16845e05f8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5MHuU22uqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Sneakers/sneaker-generator-master')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZkmSU0E28Gz",
        "colab_type": "code",
        "outputId": "aa024112-0095-4b12-928c-b0e97169b0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization, Dense, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdO8xt053EQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(dataset_path, batch_size, image_shape):\n",
        "    dataset_generator = ImageDataGenerator()\n",
        "    dataset_generator = dataset_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "\n",
        "    return dataset_generator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toKEjzoJiN6-",
        "colab_type": "code",
        "outputId": "ae83b0de-5dec-4215-a430-27ff4ee462d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "images[0].shape\n",
        "dataset_generator = ImageDataGenerator(images)\n",
        "type(dataset_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.preprocessing.image.ImageDataGenerator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdecmFVl3NCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the discriminator model. This model tries to classify images as real\n",
        "# or fake.\n",
        "def construct_discriminator(image_shape):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform',\n",
        "                             input_shape=(image_shape)))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(1))\n",
        "    discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=None)\n",
        "\n",
        "    print('discriminator')\n",
        "    discriminator.summary()\n",
        "\n",
        "    return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyLiOlst3b3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the generator model. This model has an input of random noise and\n",
        "# generates an image that will try mislead the discriminator.\n",
        "def construct_generator():\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(units=16 * 16 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(16, 16, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=None)\n",
        "\n",
        "    print('generator')\n",
        "    generator.summary()\n",
        "\n",
        "    return generator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtyz-Jjg3f2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displays a figure of the generated images and saves them in as .png image\n",
        "def save_generated_images(generated_images, epoch, batch_number):\n",
        "\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = str(epoch + 1) + '_batch' + str(batch_number + 1) + '.png'\n",
        "\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Adp3Y373jlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main train function\n",
        "def train_dcgan(batch_size, epochs, image_shape, dataset_path):\n",
        "    # Build the adversarial model that consists in the generator output\n",
        "    # connected to the discriminator\n",
        "    generator = construct_generator()\n",
        "    discriminator = construct_discriminator(image_shape)\n",
        "\n",
        "    gan = Sequential()\n",
        "    # Only false for the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                metrics=None)\n",
        "\n",
        "    # Create a dataset Generator with help of keras\n",
        "    dataset_generator = load_dataset('/content/drive/My Drive/Sneakers/sneaker-generator-master/dataset' , 64 , (256,256,3))\n",
        "\n",
        "    # 2719 is the total number of images on the dataset\n",
        "    number_of_batches = int(2719 / batch_size)\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allo plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Let's train the DCGAN for n epochs\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \" :\")\n",
        "\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Get the current batch and normalize the images between -1 and 1\n",
        "            real_images = dataset_generator.next()\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size,) + (1, 1, 100))\n",
        "\n",
        "            # Generate images\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                      np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size * 2,) +\n",
        "                                     (1, 1, 100))\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            '''if((batch_number + 1) % 5 == 0 and\n",
        "               current_batch_size == batch_size):\n",
        "                save_generated_images(generated_images, epoch, batch_number)'''\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            # Display and plot the results\n",
        "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                  str(number_of_batches) +\n",
        "                  \" generator loss | discriminator loss : \" +\n",
        "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
        "                  str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Save the model weights each 5 epochs\n",
        "        '''if (epoch + 1) % 100 == 0:\n",
        "            discriminator.trainable = True\n",
        "            save_generated_images(generated_images, epoch, batch_number)\n",
        "            generator.save_weights('/output/generator_weights%d.h5' % epoch)\n",
        "            discriminator.save_weights('/output/discriminator_weights%d.h5' % epoch)'''\n",
        "\n",
        "    # Each epoch update the loss graphs\n",
        "    plt.figure(1)\n",
        "    plt.plot(batches, adversarial_loss, color='green',\n",
        "             label='Generator Loss')\n",
        "    plt.plot(batches, discriminator_loss, color='blue',\n",
        "             label='Discriminator Loss')\n",
        "    plt.title(\"DCGAN Train\")\n",
        "    plt.xlabel(\"Batch Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    if epoch == 0:\n",
        "        plt.legend()\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()\n",
        "    plt.savefig('trainingLossPlot.png')\n",
        "\n",
        "    discriminator.trainable = True\n",
        "    save_generated_images(generated_images, epoch, batch_number)\n",
        "    generator.save_weights('generator_weights.h5')\n",
        "    discriminator.save_weights('discriminator_weights.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT-V2Oop5Ab4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    dataset_path = '/dataset'\n",
        "    batch_size = 64\n",
        "    image_shape = (256, 256, 3)\n",
        "    epochs = 30\n",
        "    train_dcgan(batch_size, epochs,\n",
        "                image_shape, dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5QHz0gF5CJK",
        "colab_type": "code",
        "outputId": "19eaca25-e675-4940-d618-729997dc2d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generator\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 1, 1, 131072)      13238272  \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_25 (Conv2DT (None, 32, 32, 256)       3277056   \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_26 (Conv2DT (None, 64, 64, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_27 (Conv2DT (None, 128, 128, 64)      204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_28 (Conv2DT (None, 256, 256, 3)       4803      \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 256, 256, 3)       0         \n",
            "=================================================================\n",
            "Total params: 17,548,163\n",
            "Trainable params: 17,546,243\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "discriminator\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 128, 128, 64)      4864      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 64, 64, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 32, 32, 256)       819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 16, 16, 512)       3277312   \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 131073    \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,441,217\n",
            "Trainable params: 4,439,425\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "Found 2735 images belonging to 1 classes.\n",
            "Epoch 1/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 4.4059973 | 4.6794634 - batch took 48.24385976791382 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 13.260814 | 2.863506 - batch took 28.120877027511597 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 0.8333974 | 2.3966575 - batch took 29.749894857406616 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 13.244195 | 12.433997 - batch took 27.98331356048584 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 9.583986 | 2.51046 - batch took 27.862164735794067 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.3995395 | 2.0220993 - batch took 28.682743787765503 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 14.514147 | 8.140466 - batch took 28.11882710456848 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 12.033129 | 5.699609 - batch took 28.07313323020935 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 6.615555 | 2.4365878 - batch took 28.214208602905273 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 3.6898746 | 1.635153 - batch took 29.162212371826172 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 14.476536 | 6.7695613 - batch took 28.64369487762451 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 14.627488 | 13.531179 - batch took 27.816396713256836 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 13.967574 | 4.3892345 - batch took 27.135798454284668 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 0.885577 | 2.1579752 - batch took 27.934773445129395 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 14.13862 | 11.139166 - batch took 27.826239585876465 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 14.559412 | 2.6209838 - batch took 26.9509220123291 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 14.487408 | 9.211196 - batch took 30.888139009475708 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 14.37421 | 3.0005507 - batch took 28.008812189102173 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 13.900433 | 2.8491888 - batch took 28.86706256866455 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 12.435057 | 2.757918 - batch took 28.954721212387085 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 10.1247425 | 2.3368714 - batch took 28.362663507461548 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 10.246195 | 2.0737555 - batch took 28.3260498046875 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.7657356 | 1.8629526 - batch took 27.607860565185547 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 14.316434 | 2.9651556 - batch took 26.391273260116577 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 14.153627 | 14.929371 - batch took 29.386462450027466 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 12.229712 | 14.430743 - batch took 27.22455620765686 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 4.1378565 | 9.395896 - batch took 27.980276346206665 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 10.63656 | 3.9088578 - batch took 30.452138662338257 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.8992524 | 6.1341057 - batch took 28.011088132858276 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 8.539091 | 4.8337035 - batch took 26.84273910522461 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.7772603 | 3.538946 - batch took 28.090585470199585 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 8.814389 | 2.6212473 - batch took 27.78397560119629 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.3362656 | 5.7904186 - batch took 28.537415027618408 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 9.734661 | 3.048984 - batch took 27.41277551651001 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.4626815 | 6.186818 - batch took 27.928608894348145 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 6.0975914 | 1.9160718 - batch took 26.94020366668701 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 5.091444 | 5.3373723 - batch took 28.33870244026184 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 7.0650134 | 2.8550076 - batch took 29.329211473464966 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 5.81456 | 4.2354198 - batch took 27.696961164474487 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 4.276238 | 1.0640073 - batch took 30.704911470413208 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 5.366289 | 3.600418 - batch took 28.195071697235107 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.5681906 | 4.212695 - batch took 27.725046634674072 s.\n",
            "Epoch 2/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.8699892 | 1.2113076 - batch took 26.309342622756958 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 4.985156 | 3.4878669 - batch took 4.545303821563721 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.6085215 | 3.8792918 - batch took 4.540889263153076 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 3.6661835 | 0.9795593 - batch took 4.514744281768799 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 4.057877 | 5.28469 - batch took 4.611910104751587 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 3.65442 | 2.034008 - batch took 4.585059881210327 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 4.9081264 | 2.2413583 - batch took 4.547189950942993 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 4.78607 | 3.1587338 - batch took 4.514380931854248 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.7155428 | 1.4500852 - batch took 4.542935371398926 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 5.4914494 | 2.13721 - batch took 4.524631500244141 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 4.322238 | 6.3964677 - batch took 4.515550136566162 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 4.669404 | 3.454609 - batch took 4.5064332485198975 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.837181 | 2.2009158 - batch took 4.525003910064697 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 4.6073546 | 2.3927114 - batch took 4.539291858673096 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 4.91438 | 4.25272 - batch took 4.520057678222656 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 3.42616 | 3.9930062 - batch took 4.510785818099976 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 3.488554 | 1.6808181 - batch took 4.537552118301392 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 3.1111503 | 1.9890206 - batch took 4.516319513320923 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.9560387 | 2.2613235 - batch took 4.5244221687316895 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 3.643336 | 1.529965 - batch took 4.539129972457886 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 3.8077197 | 3.6205902 - batch took 4.518216133117676 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.9978104 | 2.5552535 - batch took 4.513339281082153 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 3.1982977 | 1.8602101 - batch took 4.519909858703613 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.924784 | 3.3307967 - batch took 4.511501789093018 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.9793987 | 3.6073256 - batch took 4.522610187530518 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 3.254827 | 1.7160211 - batch took 4.525564193725586 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 4.031719 | 3.4508297 - batch took 4.523702144622803 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 3.2243514 | 3.6748402 - batch took 4.537431240081787 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 3.840799 | 1.9502798 - batch took 4.522181272506714 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 6.834568 | 3.306424 - batch took 4.526100397109985 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 0.49512458 | 1.6179713 - batch took 4.528856515884399 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 0.9881313 | 0.96114254 - batch took 4.521530389785767 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.096381 | 0.85837567 - batch took 4.550417900085449 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 6.2512727 | 1.4989405 - batch took 4.497960567474365 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 5.7018485 | 4.8722734 - batch took 4.515545845031738 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 3.2379427 | 2.6640754 - batch took 4.516308546066284 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 3.183875 | 1.0602692 - batch took 4.528130769729614 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.9239004 | 1.2817734 - batch took 4.529285430908203 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 4.421179 | 1.447449 - batch took 4.5351738929748535 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 5.5534925 | 2.508738 - batch took 4.507339954376221 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.4238572 | 2.930448 - batch took 4.535629987716675 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 5.0599074 | 1.620642 - batch took 4.516765356063843 s.\n",
            "Epoch 3/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 3.728588 | 3.2256048 - batch took 4.5381364822387695 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.7425606 | 2.4495807 - batch took 3.5024609565734863 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 4.364591 | 1.6543586 - batch took 4.524348735809326 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 3.6729274 | 4.9387207 - batch took 4.513777256011963 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.5895638 | 2.475417 - batch took 4.528356075286865 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 3.135426 | 1.2287501 - batch took 4.508556365966797 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 3.45725 | 2.4200058 - batch took 4.533982753753662 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 3.7250266 | 3.188325 - batch took 4.5494115352630615 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 3.8830562 | 2.9320774 - batch took 4.513991117477417 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 4.257472 | 3.0144482 - batch took 4.535308122634888 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 5.6778393 | 4.472181 - batch took 4.507714033126831 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 3.7751865 | 2.671186 - batch took 4.524757146835327 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.5176973 | 2.653756 - batch took 4.543930768966675 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.8785152 | 0.920823 - batch took 4.519488573074341 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 4.026563 | 2.485645 - batch took 4.513644456863403 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.6528525 | 2.6365242 - batch took 4.5122880935668945 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.484523 | 1.0082271 - batch took 4.512992858886719 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 3.3272743 | 1.7548945 - batch took 4.520455837249756 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2025855 | 1.8099015 - batch took 4.52907395362854 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 3.7786062 | 1.508816 - batch took 4.542121410369873 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 4.6968803 | 3.5515685 - batch took 4.526538372039795 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 3.691236 | 2.9001844 - batch took 4.520075798034668 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 3.303206 | 2.4318252 - batch took 4.514098167419434 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.7814536 | 2.548648 - batch took 4.530222654342651 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.4902322 | 2.438412 - batch took 4.523715496063232 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 3.0579524 | 1.6696525 - batch took 4.51912522315979 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 3.3617177 | 2.2285442 - batch took 4.5211875438690186 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.8370447 | 2.2617288 - batch took 4.511270523071289 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.8159976 | 1.6422063 - batch took 4.528010368347168 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 3.0316687 | 2.0097702 - batch took 4.525994777679443 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.6626072 | 1.3597367 - batch took 4.515200614929199 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 3.4261713 | 1.5286639 - batch took 4.54741644859314 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 3.2081451 | 1.53724 - batch took 4.565337896347046 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 3.942386 | 1.9389429 - batch took 4.49833607673645 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.3458424 | 1.8165014 - batch took 4.500710487365723 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.561335 | 0.9163639 - batch took 4.520312309265137 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.9898038 | 1.2064018 - batch took 4.546483993530273 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 4.5006166 | 2.4404736 - batch took 4.514425992965698 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.892611 | 1.8491548 - batch took 4.5124406814575195 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 6.2527113 | 2.5757937 - batch took 4.510823726654053 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.8375572 | 3.350819 - batch took 4.522557020187378 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 5.6384687 | 3.0115075 - batch took 4.531680345535278 s.\n",
            "Epoch 4/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.3521075 | 4.0033264 - batch took 4.518566370010376 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 3.2383695 | 1.6722213 - batch took 4.531428813934326 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 3.5100944 | 1.8488407 - batch took 3.483166456222534 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 4.0655727 | 3.00217 - batch took 4.502857446670532 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.635311 | 2.3644958 - batch took 4.553496360778809 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 3.4498153 | 2.0155582 - batch took 4.535690784454346 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.2039733 | 2.5547404 - batch took 4.527167558670044 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.59546 | 1.4059772 - batch took 4.514615774154663 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.4125433 | 1.6353106 - batch took 4.505768537521362 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.768805 | 1.5885801 - batch took 4.529937505722046 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.9433837 | 1.4549369 - batch took 4.53177547454834 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.8500044 | 1.3152668 - batch took 4.52220892906189 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.5989974 | 2.7239885 - batch took 4.52054238319397 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.9951551 | 1.1463468 - batch took 4.523423910140991 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.620846 | 1.0399475 - batch took 4.514537334442139 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 6.6385374 | 3.4113324 - batch took 4.52789044380188 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 3.0521767 | 4.0216393 - batch took 4.541473150253296 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 4.3517094 | 5.674361 - batch took 4.532620191574097 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 3.465986 | 3.145708 - batch took 4.535415887832642 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 3.4592474 | 3.4670625 - batch took 4.509013652801514 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.309514 | 2.372654 - batch took 4.52296781539917 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.2220368 | 1.7676938 - batch took 4.525399446487427 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.1911533 | 1.1562271 - batch took 4.530275106430054 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.5294745 | 2.149743 - batch took 4.51710844039917 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.384674 | 3.499504 - batch took 4.544977903366089 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.6021812 | 1.9716554 - batch took 4.528211355209351 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.42068 | 1.9638096 - batch took 4.5207672119140625 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3907928 | 1.3637381 - batch took 4.5189902782440186 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.5960805 | 1.3130362 - batch took 4.5395588874816895 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 4.0785193 | 2.3209252 - batch took 4.51640772819519 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.8446167 | 1.9032234 - batch took 4.52667760848999 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 4.9137807 | 1.7200555 - batch took 4.509793043136597 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 4.2186437 | 3.0708597 - batch took 4.528093576431274 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 3.2782016 | 2.5179253 - batch took 4.522036075592041 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 3.9032183 | 1.820288 - batch took 4.546450614929199 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 3.8797488 | 2.2058632 - batch took 4.555720329284668 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 3.0725684 | 1.8038809 - batch took 4.520475625991821 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.6488059 | 1.4839462 - batch took 4.505469799041748 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 4.0431 | 2.307994 - batch took 4.502120733261108 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.7801242 | 2.256678 - batch took 4.510761022567749 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 3.607799 | 1.6437206 - batch took 4.529777526855469 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.839963 | 2.5228744 - batch took 4.521228313446045 s.\n",
            "Epoch 5/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 4.297651 | 1.9931165 - batch took 4.523985862731934 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.214843 | 2.0750701 - batch took 4.5127785205841064 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 4.0730896 | 1.3968308 - batch took 4.52261757850647 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 4.077655 | 2.724512 - batch took 3.5074448585510254 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.9065485 | 1.794595 - batch took 4.5300562381744385 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 4.431698 | 3.1373386 - batch took 4.550841331481934 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.8484366 | 2.511258 - batch took 4.523966312408447 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 4.69143 | 1.7439283 - batch took 4.514334678649902 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.4681708 | 1.9509864 - batch took 4.541398286819458 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 3.5622005 | 1.0982025 - batch took 4.503849744796753 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.0702899 | 1.7820266 - batch took 4.539357900619507 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.2194543 | 0.871414 - batch took 4.508738279342651 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 3.3344052 | 1.6223686 - batch took 4.5187389850616455 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 3.0852435 | 2.7434156 - batch took 4.5208446979522705 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.8628557 | 1.3087876 - batch took 4.5210630893707275 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 3.536042 | 1.4615494 - batch took 4.518221616744995 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 3.295661 | 2.5837753 - batch took 4.562601566314697 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.5525675 | 1.8973101 - batch took 4.586318492889404 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.82731 | 1.7893238 - batch took 4.539273262023926 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.6096663 | 1.513779 - batch took 4.530818939208984 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 3.496501 | 1.831954 - batch took 4.53581690788269 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.351122 | 2.265168 - batch took 4.539882183074951 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 3.5954182 | 1.7524432 - batch took 4.539677858352661 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.5118594 | 2.870901 - batch took 4.536271810531616 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.2362323 | 1.9869287 - batch took 4.535029411315918 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.479988 | 1.883323 - batch took 4.5036845207214355 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.4132652 | 1.9359244 - batch took 4.531816244125366 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.9229138 | 1.3721862 - batch took 4.513418197631836 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 3.6176653 | 2.7658472 - batch took 4.531004428863525 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.6269348 | 2.3473382 - batch took 4.516936779022217 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 3.9168541 | 2.2787735 - batch took 4.521926403045654 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.586857 | 2.8884938 - batch took 4.512654542922974 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.992699 | 2.4485886 - batch took 4.535689115524292 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.4484646 | 1.4949145 - batch took 4.52266788482666 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.9473581 | 1.981003 - batch took 4.537219047546387 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.097963 | 1.8644671 - batch took 4.524966478347778 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.5181231 | 1.3427147 - batch took 4.533863306045532 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 3.3379283 | 2.5761027 - batch took 4.5246262550354 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.309434 | 2.2500167 - batch took 4.517871141433716 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.5559142 | 1.9165838 - batch took 4.51705265045166 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.8747091 | 1.9102532 - batch took 4.534592390060425 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.5782208 | 2.4207954 - batch took 4.528241157531738 s.\n",
            "Epoch 6/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.7643142 | 1.8955597 - batch took 4.52393651008606 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.1530566 | 1.94885 - batch took 4.5230584144592285 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.8550239 | 2.1034892 - batch took 4.534433364868164 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 3.435534 | 2.5251937 - batch took 4.5193846225738525 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 3.1433852 | 1.7421 - batch took 3.5100507736206055 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.6146089 | 1.9250526 - batch took 4.517848014831543 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 3.0193338 | 1.8870399 - batch took 4.514434337615967 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.0013814 | 2.0885305 - batch took 4.501906156539917 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.6656668 | 2.019099 - batch took 4.516818046569824 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.037043 | 1.6705952 - batch took 4.5310328006744385 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.2151208 | 1.903249 - batch took 4.528764724731445 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.8004761 | 1.406307 - batch took 4.530903339385986 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.7729971 | 1.9469472 - batch took 4.529805660247803 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 4.2249694 | 3.1704712 - batch took 4.5315101146698 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.7388504 | 3.5061255 - batch took 4.53035306930542 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.8997536 | 3.2919083 - batch took 4.5267603397369385 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.819725 | 1.7968171 - batch took 4.542693614959717 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.1991148 | 3.3764353 - batch took 4.524924039840698 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2102642 | 1.9503493 - batch took 4.562628269195557 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.0911696 | 2.1655874 - batch took 4.564094305038452 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.4604292 | 1.7443795 - batch took 4.530757904052734 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.6688104 | 2.099371 - batch took 4.554771661758423 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.2094417 | 2.5707018 - batch took 4.517269134521484 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.0322163 | 2.5221376 - batch took 4.530173301696777 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 3.403261 | 2.950261 - batch took 4.527024507522583 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.1711159 | 2.5531762 - batch took 4.528399467468262 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.3534362 | 1.7718743 - batch took 4.520623683929443 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.776124 | 2.2328205 - batch took 4.518671751022339 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.3032713 | 1.5674772 - batch took 4.541904449462891 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 3.0658216 | 2.3544178 - batch took 4.532183647155762 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.0549932 | 2.053074 - batch took 4.529474258422852 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.008774 | 1.5958359 - batch took 4.520097970962524 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.9814615 | 1.9005753 - batch took 4.532513380050659 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.068161 | 2.4384952 - batch took 4.522870063781738 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.2306461 | 2.1433616 - batch took 4.5188727378845215 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.5814703 | 1.8404609 - batch took 4.518834352493286 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.549697 | 1.956876 - batch took 4.5193634033203125 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.6886396 | 3.1291919 - batch took 4.509743690490723 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.7403696 | 2.3881927 - batch took 4.516691446304321 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.8197494 | 2.5276523 - batch took 4.527244329452515 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.1096811 | 2.2177124 - batch took 4.553013563156128 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.554072 | 2.2706685 - batch took 4.526017904281616 s.\n",
            "Epoch 7/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.8225436 | 1.6596857 - batch took 4.5215582847595215 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 3.039818 | 1.4350486 - batch took 4.5918803215026855 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 3.3806796 | 3.606957 - batch took 4.585416793823242 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.5171702 | 2.939558 - batch took 4.530740022659302 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.9782479 | 3.3364594 - batch took 4.544550657272339 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 3.108445 | 2.7098083 - batch took 3.5070154666900635 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.8723856 | 2.6640332 - batch took 4.531666278839111 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 3.1814227 | 1.9221426 - batch took 4.523859262466431 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.1652837 | 2.7325814 - batch took 4.520040988922119 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.7666888 | 2.230005 - batch took 4.52276873588562 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.0680747 | 2.4312077 - batch took 4.531919717788696 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 3.233108 | 2.1065423 - batch took 4.5225396156311035 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.6932302 | 2.1379802 - batch took 4.53923225402832 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.4724874 | 2.6271305 - batch took 4.5174877643585205 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.9143171 | 2.1664634 - batch took 4.530201196670532 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.1178732 | 2.1246643 - batch took 4.521952390670776 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.3669012 | 2.2453074 - batch took 4.513675928115845 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.4080591 | 2.1339426 - batch took 4.523481369018555 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.6987884 | 2.2128234 - batch took 4.508572578430176 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9250963 | 2.2647548 - batch took 4.5213563442230225 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.2763567 | 1.3023775 - batch took 4.515992641448975 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.0760489 | 2.4658594 - batch took 4.535226583480835 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.270983 | 1.6163398 - batch took 4.5387256145477295 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.1356583 | 2.3666615 - batch took 4.51485538482666 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.3267908 | 1.7713461 - batch took 4.5270490646362305 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.1612048 | 2.6134686 - batch took 4.534630298614502 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.470436 | 2.118256 - batch took 4.53298807144165 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3795433 | 1.8606833 - batch took 4.519004583358765 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.8005295 | 1.7523401 - batch took 4.518294334411621 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 3.5030158 | 1.6330364 - batch took 4.532756567001343 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.3398486 | 2.491329 - batch took 4.521013021469116 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 3.1319308 | 1.950592 - batch took 4.513040781021118 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.7695414 | 2.5560896 - batch took 4.518298387527466 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 3.0041332 | 1.8704998 - batch took 4.528806447982788 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.2992692 | 2.3788352 - batch took 4.51974630355835 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.4965973 | 3.570532 - batch took 4.507277965545654 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.1634347 | 1.2286154 - batch took 4.531795024871826 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.4334471 | 3.1104736 - batch took 4.532239198684692 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.177731 | 1.3829178 - batch took 4.533209323883057 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.942151 | 1.8339021 - batch took 4.53042459487915 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.242538 | 1.5033152 - batch took 4.5072736740112305 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.2184043 | 2.0870934 - batch took 4.522375583648682 s.\n",
            "Epoch 8/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.2415779 | 1.9855014 - batch took 4.52491021156311 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.9337113 | 1.7510121 - batch took 4.512853145599365 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.394369 | 1.9013857 - batch took 4.552189588546753 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.5609899 | 2.2698965 - batch took 4.518892765045166 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.998894 | 1.9965589 - batch took 4.536375522613525 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.9230645 | 1.7839055 - batch took 4.509201526641846 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.009983 | 2.1026325 - batch took 3.5025594234466553 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 3.3226771 | 2.0036075 - batch took 4.540353298187256 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.6143882 | 3.426674 - batch took 4.524609804153442 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.8581944 | 2.1385384 - batch took 4.517831563949585 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 3.015265 | 2.7016344 - batch took 4.5168116092681885 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.01861 | 2.8969836 - batch took 4.5165040493011475 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.6019032 | 1.2327383 - batch took 4.522023677825928 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 3.0468974 | 2.663364 - batch took 4.522486686706543 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.9552519 | 1.9872136 - batch took 4.52245306968689 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.7065148 | 2.3699093 - batch took 4.524629831314087 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.3357735 | 2.2601578 - batch took 4.519582033157349 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.1482239 | 1.7793415 - batch took 4.534106969833374 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.6392062 | 2.0248778 - batch took 4.525363445281982 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.4394946 | 2.232728 - batch took 4.540447950363159 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.16099 | 2.193735 - batch took 4.519267797470093 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.8246615 | 1.5757608 - batch took 4.522549390792847 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.2544649 | 1.7278432 - batch took 4.522036552429199 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.237217 | 2.5627499 - batch took 4.526137113571167 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.3459442 | 1.9184651 - batch took 4.514903783798218 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.7703686 | 2.195043 - batch took 4.5222249031066895 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.0970361 | 2.4703178 - batch took 4.513118267059326 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.1394882 | 1.6257427 - batch took 4.517492771148682 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 3.0881891 | 2.2379599 - batch took 4.553114891052246 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.5440291 | 2.5328298 - batch took 4.566635847091675 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 3.7217927 | 1.9441736 - batch took 4.507088899612427 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.1405425 | 2.7057972 - batch took 4.523706674575806 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.7422788 | 1.7495224 - batch took 4.507055759429932 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.3695846 | 2.2653532 - batch took 4.52683162689209 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.4276385 | 2.4276946 - batch took 4.507207155227661 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.7444425 | 2.4612918 - batch took 4.518253803253174 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.9109342 | 2.639103 - batch took 4.520112752914429 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.5432858 | 2.4340668 - batch took 4.541291952133179 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.173153 | 1.7825372 - batch took 4.5312371253967285 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.2624002 | 1.104092 - batch took 4.528516054153442 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.1714544 | 2.0714376 - batch took 4.526038408279419 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.8232026 | 1.2803566 - batch took 4.517669677734375 s.\n",
            "Epoch 9/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.4405239 | 2.0047317 - batch took 4.51618766784668 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.0188956 | 1.6116818 - batch took 4.52628493309021 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.2153125 | 1.4377183 - batch took 4.511934757232666 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.9337807 | 1.6598433 - batch took 4.521102666854858 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.5618324 | 1.777134 - batch took 4.515179395675659 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.6665 | 2.2000437 - batch took 4.531328201293945 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 3.2458205 | 2.6258547 - batch took 4.524862766265869 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.9533868 | 3.0043404 - batch took 3.4960076808929443 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 3.2392292 | 2.1627493 - batch took 4.533256769180298 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 3.682731 | 2.4888525 - batch took 4.516863584518433 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.917005 | 2.2053168 - batch took 4.527482986450195 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.6583772 | 2.2072961 - batch took 4.541269779205322 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.357657 | 1.7515775 - batch took 4.521303415298462 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 3.1711257 | 1.6717525 - batch took 4.520204067230225 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.3266964 | 2.2241225 - batch took 4.518920421600342 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.5641563 | 1.4764417 - batch took 4.514826059341431 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.9184158 | 1.7482452 - batch took 4.529752969741821 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.7136176 | 1.6956997 - batch took 4.517698287963867 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.1710038 | 1.8620756 - batch took 4.524460315704346 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9023758 | 1.7109458 - batch took 4.521278619766235 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.7349234 | 1.8331472 - batch took 4.517465114593506 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 4.229909 | 2.0741134 - batch took 4.522843360900879 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 3.8663776 | 3.2275074 - batch took 4.526994943618774 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.3989861 | 4.3102055 - batch took 4.5417160987854 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.6467452 | 1.2660435 - batch took 4.5277533531188965 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.2128878 | 3.3862388 - batch took 4.522534608840942 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 3.421605 | 1.2771231 - batch took 4.521157503128052 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.7996955 | 3.3271854 - batch took 4.520414352416992 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.7557535 | 1.0267254 - batch took 4.54428243637085 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 3.361661 | 1.9390616 - batch took 4.519014358520508 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.6070482 | 2.626883 - batch took 4.530653715133667 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.9378855 | 1.6671708 - batch took 4.517786502838135 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.9067881 | 2.4203088 - batch took 4.517285585403442 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.3354082 | 1.4791925 - batch took 4.540958404541016 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.8621006 | 2.0412788 - batch took 4.520057916641235 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.0337892 | 2.21341 - batch took 4.524282455444336 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 4.2863607 | 2.1810026 - batch took 4.524240732192993 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.7449224 | 2.849382 - batch took 4.531124591827393 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.4587417 | 1.622121 - batch took 4.51298189163208 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.5755959 | 1.7630191 - batch took 4.514176845550537 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.2684188 | 1.9068093 - batch took 4.527126312255859 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.5075784 | 1.930448 - batch took 4.518826007843018 s.\n",
            "Epoch 10/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.3635018 | 2.5909965 - batch took 4.518152236938477 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.1479647 | 2.1793792 - batch took 4.524982213973999 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.1122255 | 1.9350047 - batch took 4.539031505584717 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.1072514 | 1.8054614 - batch took 4.528656244277954 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 3.7947214 | 2.216973 - batch took 4.519164085388184 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.7302966 | 2.6601615 - batch took 4.519482851028442 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 3.4265575 | 2.5545874 - batch took 4.519089698791504 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.426727 | 2.8862686 - batch took 4.512984275817871 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.5114217 | 1.7951163 - batch took 3.508326292037964 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.833631 | 1.828244 - batch took 4.531075716018677 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.906953 | 2.0366726 - batch took 4.528055429458618 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.8781557 | 2.3058758 - batch took 4.518618822097778 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 3.3272939 | 2.3349762 - batch took 4.524425029754639 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.4540722 | 2.6521745 - batch took 4.555529594421387 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.1367223 | 1.4904003 - batch took 4.533762216567993 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.289885 | 1.7600516 - batch took 4.505250930786133 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.6699731 | 1.4974536 - batch took 4.516693830490112 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.1858609 | 1.6839142 - batch took 4.5245301723480225 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 1.9140316 | 1.7210481 - batch took 4.513494968414307 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.526802 | 1.2048876 - batch took 4.520351886749268 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.0442805 | 1.3910855 - batch took 4.523933172225952 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 3.3190362 | 1.5862747 - batch took 4.522649049758911 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.9623467 | 1.9491278 - batch took 4.51892352104187 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.862138 | 1.9073558 - batch took 4.512694358825684 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.571387 | 2.0847223 - batch took 4.523702621459961 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 3.774704 | 1.8143476 - batch took 4.547030448913574 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.3474703 | 3.0460982 - batch took 4.523108243942261 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.5195065 | 2.100691 - batch took 4.537501096725464 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.0856605 | 1.3942808 - batch took 4.517711162567139 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.715766 | 1.6553271 - batch took 4.513899087905884 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.2765791 | 1.7778134 - batch took 4.500656843185425 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.8366597 | 1.077618 - batch took 4.523908615112305 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.5715652 | 1.2770344 - batch took 4.522508144378662 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.9383316 | 2.0764313 - batch took 4.5303795337677 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.7409916 | 2.1421046 - batch took 4.521202087402344 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.1177359 | 2.8433046 - batch took 4.524489402770996 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.065865 | 1.6868944 - batch took 4.519066572189331 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.731288 | 1.7356279 - batch took 4.547590255737305 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.6779408 | 2.5149903 - batch took 4.533924341201782 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 3.153214 | 2.8783693 - batch took 4.523386478424072 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.5187964 | 2.270197 - batch took 4.520077466964722 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.525229 | 1.5627518 - batch took 4.51517653465271 s.\n",
            "Epoch 11/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.66398 | 1.1123154 - batch took 4.512118101119995 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.7438253 | 1.40545 - batch took 4.5051751136779785 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.5266707 | 1.412956 - batch took 4.518934011459351 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.6455357 | 1.274079 - batch took 4.5371081829071045 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.148273 | 1.7134713 - batch took 4.531565427780151 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 3.4884334 | 1.742282 - batch took 4.51989483833313 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.5748312 | 3.0241299 - batch took 4.520936489105225 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.2820878 | 1.5597575 - batch took 4.564084768295288 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.5354834 | 1.9967663 - batch took 4.5343077182769775 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.022635 | 1.9138955 - batch took 3.496397018432617 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.4176555 | 1.3534575 - batch took 4.530239820480347 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.6667442 | 2.0696578 - batch took 4.529597997665405 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.8800356 | 1.989666 - batch took 4.560043573379517 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.9570992 | 2.2694664 - batch took 4.526352882385254 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.4123096 | 2.6596148 - batch took 4.533288240432739 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.8627937 | 1.6661499 - batch took 4.528906583786011 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.074678 | 1.5955594 - batch took 4.496668338775635 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.3710446 | 1.9838272 - batch took 4.496776342391968 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.1077626 | 2.0028384 - batch took 4.52508020401001 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.9038582 | 3.4998474 - batch took 4.5393736362457275 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.924889 | 2.720007 - batch took 4.529401540756226 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 3.4550586 | 1.8470331 - batch took 4.5172951221466064 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.2491518 | 2.9482598 - batch took 4.519697904586792 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 3.5073116 | 1.6936393 - batch took 4.518946409225464 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.7004677 | 2.4928892 - batch took 4.5060834884643555 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.5518482 | 2.0252283 - batch took 4.511955738067627 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.9775671 | 1.4050016 - batch took 4.523447275161743 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3609838 | 1.7103122 - batch took 4.529515504837036 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.0363312 | 1.5028439 - batch took 4.532659530639648 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.6233506 | 1.710601 - batch took 4.5364580154418945 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.0023336 | 2.1812286 - batch took 4.527144908905029 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.6164794 | 2.0818303 - batch took 4.54317569732666 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.1093826 | 2.1328626 - batch took 4.522338628768921 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.6678348 | 2.051922 - batch took 4.542311668395996 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.4465532 | 1.8018473 - batch took 4.515879154205322 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.082849 | 2.1373253 - batch took 4.515392541885376 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.294179 | 1.5820923 - batch took 4.526355504989624 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.1915722 | 1.9056048 - batch took 4.516203880310059 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.9249234 | 1.7516582 - batch took 4.511794805526733 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.3432155 | 1.5375721 - batch took 4.522040367126465 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.5528312 | 1.7076747 - batch took 4.56603741645813 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.5267847 | 2.254099 - batch took 4.5931127071380615 s.\n",
            "Epoch 12/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.7443051 | 1.6715472 - batch took 4.536944627761841 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.6118095 | 1.695889 - batch took 4.538464546203613 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.0283885 | 1.8518097 - batch took 4.522845268249512 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.647352 | 1.5346196 - batch took 4.542229175567627 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.3891573 | 1.955743 - batch took 4.52938175201416 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.594626 | 1.7130866 - batch took 4.526944637298584 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.266067 | 1.3982172 - batch took 4.531635284423828 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 3.4606724 | 3.182909 - batch took 4.527469158172607 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.749096 | 1.2715799 - batch took 4.508079528808594 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 1.9566493 | 2.5410054 - batch took 4.51378607749939 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.9186378 | 1.3915384 - batch took 3.508220672607422 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.6485279 | 3.6585302 - batch took 4.5354883670806885 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.5479689 | 1.6727818 - batch took 4.517746448516846 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.1183536 | 2.2266443 - batch took 4.543227195739746 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.8866123 | 1.100303 - batch took 4.517204999923706 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.7687743 | 1.3999457 - batch took 4.53517484664917 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.5113075 | 1.2856544 - batch took 4.532707691192627 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 3.3544483 | 2.1116486 - batch took 4.529411554336548 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.507719 | 2.489081 - batch took 4.5661609172821045 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.7594154 | 1.5409654 - batch took 4.516149282455444 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.4473693 | 2.5966148 - batch took 4.5228071212768555 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.6266847 | 2.1203246 - batch took 4.5464818477630615 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.173597 | 1.8489386 - batch took 4.525828838348389 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.9375763 | 1.9210072 - batch took 4.540383815765381 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.2944152 | 1.6952962 - batch took 4.536915063858032 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.947419 | 1.9336619 - batch took 4.539151668548584 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.8363261 | 2.7341774 - batch took 4.542197942733765 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3140028 | 1.5811377 - batch took 4.534469842910767 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 3.1405993 | 1.6167274 - batch took 4.525625944137573 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.62691 | 1.6419094 - batch took 4.532061576843262 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.5588245 | 1.4665679 - batch took 4.537800550460815 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.105579 | 1.2683988 - batch took 4.515597105026245 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.1091802 | 2.2338436 - batch took 4.539851903915405 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.2021313 | 1.8079889 - batch took 4.517090559005737 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.2625494 | 2.2465904 - batch took 4.522629499435425 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.3129282 | 1.8612987 - batch took 4.518023490905762 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 1.8083107 | 1.435076 - batch took 4.5111517906188965 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.6398084 | 1.6038911 - batch took 4.534426927566528 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.1135364 | 1.6842054 - batch took 4.541715860366821 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.4799397 | 1.845535 - batch took 4.52005672454834 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.5051408 | 1.8771536 - batch took 4.515353679656982 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.5933995 | 2.0495176 - batch took 4.526463747024536 s.\n",
            "Epoch 13/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.8680977 | 2.3983026 - batch took 4.542628049850464 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.010773 | 2.1751332 - batch took 4.5189995765686035 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.575148 | 1.4340192 - batch took 4.530564069747925 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.8767145 | 2.7695198 - batch took 4.535936117172241 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.2398195 | 1.3384029 - batch took 4.5242040157318115 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.183484 | 2.466219 - batch took 4.533412218093872 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.4970815 | 1.975241 - batch took 4.545122861862183 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.6652412 | 1.5461316 - batch took 4.551486492156982 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.4340801 | 2.1493206 - batch took 4.538121461868286 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 1.9217582 | 1.941725 - batch took 4.527466297149658 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.8874725 | 1.2930392 - batch took 4.527169704437256 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.014973 | 1.915091 - batch took 3.510756254196167 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.3930154 | 1.7360184 - batch took 4.546358108520508 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.6635948 | 1.5925424 - batch took 4.520986080169678 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.4193354 | 1.8897545 - batch took 4.538457632064819 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.7941761 | 1.1565108 - batch took 4.533809661865234 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.2850823 | 1.7964137 - batch took 4.530831575393677 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.4124227 | 2.0383918 - batch took 4.517498731613159 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.0395432 | 2.7063367 - batch took 4.5336363315582275 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.09723 | 2.0115597 - batch took 4.525273323059082 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.8803154 | 1.6094449 - batch took 4.512094020843506 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.439599 | 1.5595617 - batch took 4.523423433303833 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.2327976 | 2.4174013 - batch took 4.509497404098511 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.736986 | 2.0254056 - batch took 4.5150792598724365 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.0848904 | 2.6836245 - batch took 4.534205436706543 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.399769 | 1.9338543 - batch took 4.545094013214111 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.817162 | 1.4926775 - batch took 4.5661256313323975 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 3.4626799 | 3.503892 - batch took 4.502103328704834 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.7041938 | 2.3836656 - batch took 4.491240739822388 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.9926918 | 2.7984 - batch took 4.515926361083984 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.8578876 | 2.1665025 - batch took 4.522403240203857 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.2159967 | 1.8262775 - batch took 4.497420787811279 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.8840485 | 1.7035186 - batch took 4.512653827667236 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.5301843 | 1.7227907 - batch took 4.517016649246216 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.8803518 | 1.9317758 - batch took 4.545753479003906 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.501687 | 1.7423615 - batch took 4.518176317214966 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 1.9829695 | 1.5904887 - batch took 4.535599708557129 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.0728981 | 1.9260497 - batch took 4.5115883350372314 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.9942602 | 1.5970747 - batch took 4.538214445114136 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.2261531 | 1.5820165 - batch took 4.546122074127197 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.185146 | 1.8295748 - batch took 4.5244879722595215 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.718432 | 2.0677998 - batch took 4.542153596878052 s.\n",
            "Epoch 14/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.1361384 | 2.3401394 - batch took 4.519529104232788 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.8773335 | 1.7224637 - batch took 4.521374225616455 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.4159417 | 2.0470111 - batch took 4.514209508895874 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.1316533 | 1.6832964 - batch took 4.522943496704102 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.0922556 | 1.6486716 - batch took 4.52440881729126 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.5209334 | 2.0755763 - batch took 4.526073932647705 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.613221 | 1.9504406 - batch took 4.536564588546753 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.88486 | 2.5476027 - batch took 4.525646686553955 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.1689384 | 2.3615336 - batch took 4.529423236846924 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.3540998 | 1.9911844 - batch took 4.53166389465332 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.9151132 | 2.1329465 - batch took 4.517155885696411 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.0583262 | 1.2978415 - batch took 4.530153036117554 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.9815037 | 2.3860488 - batch took 3.5065460205078125 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.183165 | 1.5759434 - batch took 4.5175604820251465 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.5693765 | 1.6326227 - batch took 4.550094842910767 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.4874058 | 2.4803066 - batch took 4.514695167541504 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.0515246 | 2.2583816 - batch took 4.518672227859497 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.182991 | 2.1206927 - batch took 4.5168092250823975 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.0753417 | 1.7790401 - batch took 4.529696226119995 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.5803347 | 1.4739845 - batch took 4.522924423217773 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.5486441 | 1.6273258 - batch took 4.536914587020874 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.5237937 | 1.8504013 - batch took 4.537684202194214 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.848557 | 1.7120394 - batch took 4.587298154830933 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.2184672 | 1.6733109 - batch took 4.5273072719573975 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.6695259 | 1.9769797 - batch took 4.549875736236572 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.8769085 | 1.8516382 - batch took 4.536712884902954 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.5617095 | 1.7803319 - batch took 4.540856122970581 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.2887988 | 1.6863029 - batch took 4.5291712284088135 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.033515 | 2.2397647 - batch took 4.528667211532593 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.5156124 | 1.7092174 - batch took 4.522770881652832 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.9867227 | 1.5795732 - batch took 4.542534112930298 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.9493619 | 2.167747 - batch took 4.493555545806885 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.8507869 | 1.8053521 - batch took 4.541067123413086 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.1901221 | 1.6875424 - batch took 4.5393147468566895 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.5803485 | 1.860198 - batch took 4.5081024169921875 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.7388711 | 1.8219681 - batch took 4.522019386291504 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.173139 | 2.1991043 - batch took 4.518660306930542 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.6680921 | 1.9508779 - batch took 4.536172389984131 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.3424883 | 1.3906435 - batch took 4.520201921463013 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.0239992 | 1.9149292 - batch took 4.509953498840332 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.2598135 | 1.9280207 - batch took 4.515661001205444 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.908849 | 1.8664005 - batch took 4.532764911651611 s.\n",
            "Epoch 15/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.7788408 | 1.6951902 - batch took 4.540821313858032 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.224155 | 1.9620295 - batch took 4.519277572631836 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.4200616 | 2.2432725 - batch took 4.516749858856201 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.7850333 | 1.7920451 - batch took 4.5372021198272705 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.0281365 | 2.419151 - batch took 4.521624326705933 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.0516877 | 2.2766442 - batch took 4.534557104110718 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.6378036 | 2.089531 - batch took 4.543703317642212 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.8298699 | 2.2009218 - batch took 4.557023286819458 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.1691992 | 1.8967701 - batch took 4.551194667816162 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.3022337 | 1.95366 - batch took 4.552347183227539 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.1873755 | 1.8651481 - batch took 4.5588219165802 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.710274 | 2.0727596 - batch took 4.5576159954071045 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.054846 | 1.5092613 - batch took 4.509205102920532 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.6415393 | 1.9566917 - batch took 3.496732234954834 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.8976163 | 1.9544373 - batch took 4.5109946727752686 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.4534574 | 1.4802506 - batch took 4.530008554458618 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.5290234 | 1.7035484 - batch took 4.522945165634155 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.7544321 | 1.2632701 - batch took 4.539997100830078 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.4301624 | 1.9593962 - batch took 4.537855863571167 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.469964 | 2.2426975 - batch took 4.511427164077759 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.741201 | 1.8695617 - batch took 4.5407044887542725 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.2366977 | 1.5509994 - batch took 4.522624731063843 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.1881328 | 2.0348012 - batch took 4.509001970291138 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.7371635 | 1.7465358 - batch took 4.517457723617554 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.3908348 | 2.0512002 - batch took 4.511939287185669 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.105011 | 2.1168852 - batch took 4.52405858039856 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.0694222 | 2.4583888 - batch took 4.511349201202393 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.286044 | 1.5809649 - batch took 4.519078493118286 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.072678 | 1.8426045 - batch took 4.533236503601074 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 3.02171 | 2.4704273 - batch took 4.535706520080566 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.8716438 | 2.6889374 - batch took 4.5311408042907715 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.2734656 | 1.6487253 - batch took 4.519958734512329 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.2374446 | 1.994396 - batch took 4.5152952671051025 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.2651548 | 2.1568227 - batch took 4.519693374633789 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.1568508 | 1.5175767 - batch took 4.514559507369995 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.694781 | 2.4711792 - batch took 4.532644271850586 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.274674 | 3.324446 - batch took 4.521322011947632 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.1414263 | 3.3114588 - batch took 4.510154485702515 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.6472316 | 1.5830337 - batch took 4.524258852005005 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.8719255 | 2.4268208 - batch took 4.519226789474487 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.5594801 | 1.2803723 - batch took 4.540059804916382 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.2284365 | 1.4935167 - batch took 4.530254602432251 s.\n",
            "Epoch 16/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.904733 | 1.6846926 - batch took 4.529902935028076 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.0221672 | 1.7801391 - batch took 4.526352405548096 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.3394747 | 1.7140675 - batch took 4.51775050163269 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.4534376 | 1.647244 - batch took 4.544417381286621 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.840067 | 3.079607 - batch took 4.512474298477173 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.0746222 | 2.3961515 - batch took 4.522412300109863 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.2207103 | 1.6689641 - batch took 4.551386117935181 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.9788647 | 1.9074659 - batch took 4.5259692668914795 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.2618864 | 2.1413136 - batch took 4.508573770523071 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.065878 | 2.1259766 - batch took 4.526969909667969 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.4355564 | 2.5962868 - batch took 4.513041973114014 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.116257 | 2.0895257 - batch took 4.518378496170044 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.1794882 | 1.9877398 - batch took 4.5240960121154785 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.4310088 | 2.0970626 - batch took 4.519220590591431 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.6077881 | 2.0398805 - batch took 3.5198585987091064 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.7793491 | 1.5243025 - batch took 4.5311830043792725 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.523265 | 2.7591357 - batch took 4.517764091491699 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.7627198 | 2.12884 - batch took 4.513885498046875 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2555299 | 2.3993082 - batch took 4.514812469482422 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.8667121 | 1.5074875 - batch took 4.534365653991699 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.2839794 | 1.8539169 - batch took 4.529162406921387 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.8167597 | 1.6008576 - batch took 4.531115770339966 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.0070508 | 1.6822512 - batch took 4.513501167297363 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.0133758 | 1.7418162 - batch took 4.535143613815308 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.6911132 | 1.9724834 - batch took 4.519962549209595 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.7255096 | 1.6591591 - batch took 4.526227712631226 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.9835494 | 1.6486083 - batch took 4.534554719924927 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.2930613 | 1.3597608 - batch took 4.524866819381714 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.4270469 | 2.1193545 - batch took 4.500298500061035 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.4280796 | 1.633076 - batch took 4.5196051597595215 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.6961124 | 1.9523268 - batch took 4.524642467498779 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.4414039 | 1.866776 - batch took 4.525017261505127 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.6550229 | 2.3686182 - batch took 4.535884618759155 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.049858 | 1.3785198 - batch took 4.5246148109436035 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.1575046 | 1.752422 - batch took 4.525607585906982 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.8640199 | 1.8208861 - batch took 4.524588584899902 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.2588027 | 2.079847 - batch took 4.510269403457642 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.4935074 | 2.9413888 - batch took 4.5895836353302 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.8395056 | 2.0772007 - batch took 4.537301540374756 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.2740445 | 1.567075 - batch took 4.497955083847046 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.8257052 | 2.0900953 - batch took 4.5115485191345215 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.8939244 | 2.4180393 - batch took 4.525432825088501 s.\n",
            "Epoch 17/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.8608682 | 1.6828551 - batch took 4.508734226226807 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.7705168 | 1.3710036 - batch took 4.515955448150635 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.3017454 | 1.5491233 - batch took 4.510295867919922 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.0521586 | 2.664401 - batch took 4.520264625549316 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.9780052 | 2.4329865 - batch took 4.529040575027466 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.8727462 | 2.2274563 - batch took 4.523001432418823 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.8446782 | 1.6834453 - batch took 4.510843515396118 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.0780227 | 1.9894698 - batch took 4.517735242843628 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.0342674 | 1.5938118 - batch took 4.526962995529175 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.270091 | 1.951751 - batch took 4.528254508972168 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.6238475 | 2.4646096 - batch took 4.515674829483032 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.6601279 | 1.9043659 - batch took 4.5358617305755615 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.0586414 | 1.9954424 - batch took 4.540247678756714 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.3810935 | 1.9593794 - batch took 4.523644208908081 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.166592 | 2.1553652 - batch took 4.5153961181640625 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.7741127 | 1.9996369 - batch took 3.4993436336517334 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.9263326 | 1.9947593 - batch took 4.537468671798706 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.8625197 | 1.7668488 - batch took 4.525068998336792 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 1.9248483 | 1.7883928 - batch took 4.520415544509888 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.1570466 | 1.7682749 - batch took 4.532864332199097 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.7259265 | 1.6656852 - batch took 4.5121307373046875 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.1572049 | 1.4897778 - batch took 4.518070220947266 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.874344 | 2.3219929 - batch took 4.521407604217529 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.7268455 | 2.8726783 - batch took 4.526615619659424 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.50953 | 2.0535536 - batch took 4.525079011917114 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.643827 | 2.4228096 - batch took 4.509027004241943 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.8488444 | 1.3966444 - batch took 4.523093223571777 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.1547918 | 1.4307632 - batch took 4.542756795883179 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.698399 | 1.9296659 - batch took 4.5278027057647705 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.5570338 | 2.0921803 - batch took 4.519717693328857 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.1298566 | 2.3200147 - batch took 4.52860426902771 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.6491098 | 2.1345522 - batch took 4.52493691444397 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.4401302 | 2.2739253 - batch took 4.525833606719971 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.4402707 | 1.571491 - batch took 4.515872001647949 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.9767747 | 2.3946345 - batch took 4.527191877365112 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.6490247 | 3.2264132 - batch took 4.514231204986572 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.515415 | 1.7069298 - batch took 4.52859354019165 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.7687753 | 1.7618052 - batch took 4.53398585319519 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.2448034 | 1.5876105 - batch took 4.530095100402832 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.0437577 | 2.1736696 - batch took 4.524716377258301 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.394466 | 1.9986589 - batch took 4.515012979507446 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.8033223 | 1.9406663 - batch took 4.523815631866455 s.\n",
            "Epoch 18/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.9999075 | 2.146768 - batch took 4.52948784828186 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.8536654 | 1.6989133 - batch took 4.515566110610962 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.2858908 | 1.5218287 - batch took 4.522528648376465 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.7339319 | 1.5531735 - batch took 4.517781496047974 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.113805 | 1.628757 - batch took 4.532517194747925 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.8302407 | 1.7314558 - batch took 4.514454364776611 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.0097299 | 1.8828694 - batch took 4.510116100311279 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.9953113 | 2.0972886 - batch took 4.52936577796936 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.212486 | 2.0469716 - batch took 4.527540922164917 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 1.6777562 | 1.9323504 - batch took 4.537198066711426 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.7710134 | 1.550941 - batch took 4.520881652832031 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.456058 | 1.6992297 - batch took 4.509763240814209 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.8927553 | 1.4262532 - batch took 4.515259265899658 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.6238732 | 1.5568471 - batch took 4.521845102310181 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.9715092 | 1.8007102 - batch took 4.523458003997803 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.4264011 | 2.4542665 - batch took 4.535264253616333 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.29203 | 1.8289008 - batch took 3.507572889328003 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.2133684 | 2.6181264 - batch took 4.525123119354248 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2911067 | 1.801234 - batch took 4.5222532749176025 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.2523537 | 2.3747265 - batch took 4.5332605838775635 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.191853 | 1.7152548 - batch took 4.522378921508789 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.280606 | 2.1880634 - batch took 4.540201902389526 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.7877852 | 1.9923435 - batch took 4.6167213916778564 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.7382712 | 1.7127994 - batch took 4.578261852264404 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.9777565 | 2.3175514 - batch took 4.530129432678223 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.1809967 | 1.4571159 - batch took 4.5276312828063965 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.8776753 | 1.6180182 - batch took 4.528243541717529 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.0195088 | 1.3887223 - batch took 4.509238958358765 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.6465654 | 2.6542046 - batch took 4.539161682128906 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.7342654 | 2.3061638 - batch took 4.522888422012329 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.8535018 | 1.1889 - batch took 4.53060507774353 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.1180985 | 2.0391607 - batch took 4.528712749481201 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.9964192 | 1.8738809 - batch took 4.5183258056640625 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.2388403 | 1.9253902 - batch took 4.5325400829315186 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.7082051 | 1.6708645 - batch took 4.5287182331085205 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.3671126 | 1.7324978 - batch took 4.52390718460083 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.2608624 | 2.3566594 - batch took 4.523736953735352 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.9360274 | 1.9795932 - batch took 4.505143880844116 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.9300864 | 2.1953368 - batch took 4.537901878356934 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.8734225 | 1.5631759 - batch took 4.5225372314453125 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.5760434 | 1.5726802 - batch took 4.525605201721191 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.0638194 | 1.56868 - batch took 4.513499021530151 s.\n",
            "Epoch 19/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.9888685 | 1.6747599 - batch took 4.529699087142944 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.9411874 | 1.791367 - batch took 4.515478610992432 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.2050471 | 1.5128019 - batch took 4.517967939376831 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.3217416 | 1.8413624 - batch took 4.527265548706055 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.7330205 | 1.8297892 - batch took 4.5451555252075195 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.173513 | 1.5193653 - batch took 4.5207977294921875 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.3529673 | 1.9773784 - batch took 4.524502277374268 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.852757 | 1.8724326 - batch took 4.513931751251221 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.1174474 | 1.6399481 - batch took 4.532898426055908 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.7717156 | 2.0565448 - batch took 4.511566162109375 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.0208254 | 1.9648639 - batch took 4.5195982456207275 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.2609258 | 2.6458483 - batch took 4.525798082351685 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.6673813 | 1.7107159 - batch took 4.527952194213867 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.380534 | 2.1841526 - batch took 4.525517225265503 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.9206208 | 1.7948301 - batch took 4.517000675201416 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.208673 | 1.5820987 - batch took 4.549167156219482 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.7118421 | 1.6403064 - batch took 4.550464391708374 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.1235235 | 1.5573224 - batch took 3.4860823154449463 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.0383534 | 1.9719126 - batch took 4.537048578262329 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9185002 | 1.6725564 - batch took 4.521625757217407 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.0451844 | 1.5976368 - batch took 4.51978325843811 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.7630421 | 1.532304 - batch took 4.50352144241333 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.8047991 | 1.6112688 - batch took 4.51665472984314 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.2763205 | 2.1166496 - batch took 4.521936655044556 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.1019726 | 1.8426814 - batch took 4.529344797134399 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.3020315 | 1.835949 - batch took 4.544512748718262 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.0157397 | 1.9674466 - batch took 4.519163131713867 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.8431207 | 1.8642952 - batch took 4.523627519607544 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.6858416 | 1.6916091 - batch took 4.523048162460327 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.0399876 | 1.8477097 - batch took 4.516053915023804 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.3279543 | 1.5240793 - batch took 4.509803056716919 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.918444 | 1.5032182 - batch took 4.513993978500366 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.4254975 | 1.5727899 - batch took 4.5387091636657715 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.7037995 | 1.9060948 - batch took 4.52041220664978 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.0470352 | 1.6948195 - batch took 4.528425216674805 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.9048479 | 1.7327608 - batch took 4.526032209396362 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.4898908 | 2.0937302 - batch took 4.510295152664185 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.1480854 | 1.967107 - batch took 4.508688926696777 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.381126 | 1.7577374 - batch took 4.527048826217651 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.8373141 | 2.6803827 - batch took 4.527790784835815 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.048687 | 1.7072487 - batch took 4.54682731628418 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.500465 | 1.5059643 - batch took 4.521238088607788 s.\n",
            "Epoch 20/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.583373 | 2.3208103 - batch took 4.532581567764282 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.7166191 | 2.9201813 - batch took 4.516443729400635 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 1.9382138 | 1.5816883 - batch took 4.519937038421631 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.8329711 | 2.0509887 - batch took 4.514034271240234 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.129192 | 1.840304 - batch took 4.530361890792847 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.0278325 | 1.5648222 - batch took 4.525355815887451 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.5116646 | 1.5885388 - batch took 4.511449337005615 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.0282774 | 2.176687 - batch took 4.548336982727051 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.0514772 | 1.6812123 - batch took 4.539607524871826 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.0118759 | 2.1134815 - batch took 4.516229629516602 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.8775196 | 1.7616956 - batch took 4.5394816398620605 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.7297843 | 2.1604686 - batch took 4.515803098678589 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.86749 | 1.8715091 - batch took 4.517242431640625 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.4632044 | 2.4675212 - batch took 4.509692907333374 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.8355544 | 2.4513521 - batch took 4.520195722579956 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.9965084 | 2.1939192 - batch took 4.521024703979492 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.4188693 | 2.130114 - batch took 4.529728412628174 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.8674002 | 1.3640543 - batch took 4.527409315109253 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 1.8871351 | 1.6488372 - batch took 3.486602306365967 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.1234136 | 1.5810344 - batch took 4.542225122451782 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.7739857 | 2.091913 - batch took 4.532796382904053 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.8434839 | 1.3593581 - batch took 4.529881954193115 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.4893837 | 1.8127613 - batch took 4.525083780288696 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.918237 | 1.9723125 - batch took 4.528331518173218 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.5078702 | 1.7376252 - batch took 4.522350549697876 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.9853504 | 2.2314358 - batch took 4.515367746353149 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.133572 | 1.9537932 - batch took 4.523883581161499 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.8960345 | 1.5527778 - batch took 4.530102968215942 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.123115 | 1.6371987 - batch took 4.511507272720337 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.408572 | 1.8793256 - batch took 4.525787115097046 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.6383905 | 1.5672357 - batch took 4.5324060916900635 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.107163 | 1.1721618 - batch took 4.523857831954956 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.2553823 | 1.3844888 - batch took 4.531668186187744 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.9159534 | 2.5261254 - batch took 4.524885654449463 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.8345227 | 1.8462025 - batch took 4.522288799285889 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.5410062 | 2.8501139 - batch took 4.50414776802063 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 1.1771545 | 1.2548609 - batch took 4.527284383773804 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 3.0375142 | 1.6756275 - batch took 4.52905535697937 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.1517031 | 2.0339131 - batch took 4.518381357192993 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.4500096 | 1.8738077 - batch took 4.524487495422363 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.1834936 | 2.0030255 - batch took 4.513127088546753 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.9014153 | 2.215656 - batch took 4.5504443645477295 s.\n",
            "Epoch 21/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.481861 | 1.6787672 - batch took 4.553547382354736 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.0241106 | 1.9187032 - batch took 4.493727922439575 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.1497717 | 1.8728461 - batch took 4.5260539054870605 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.1966858 | 1.9267477 - batch took 4.516000509262085 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.7027152 | 2.3629653 - batch took 4.530799150466919 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.2604034 | 1.369863 - batch took 4.5181052684783936 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.1273046 | 1.888314 - batch took 4.5286688804626465 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.6302993 | 2.0529275 - batch took 4.510279893875122 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.8634586 | 2.2991183 - batch took 4.519960880279541 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 1.9215009 | 1.7603153 - batch took 4.5133514404296875 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.2892294 | 2.6027312 - batch took 4.523530960083008 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.589461 | 1.790871 - batch took 4.516246318817139 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.915521 | 2.6722374 - batch took 4.541554927825928 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.9661452 | 1.7870967 - batch took 4.5210347175598145 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.0955722 | 2.1972551 - batch took 4.53788948059082 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.9779062 | 1.7860507 - batch took 4.518377304077148 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.762035 | 1.8828292 - batch took 4.534019470214844 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.1763227 | 1.6593679 - batch took 4.516726493835449 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 1.7152181 | 1.7117052 - batch took 4.524305105209351 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.230204 | 1.4132397 - batch took 3.505535125732422 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.692107 | 1.5817872 - batch took 4.526540279388428 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.5359797 | 1.4881659 - batch took 4.515355348587036 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.2439814 | 1.6658297 - batch took 4.530427932739258 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.4232333 | 1.9428822 - batch took 4.536172389984131 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.854856 | 1.6241437 - batch took 4.530648946762085 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.3238037 | 1.6173882 - batch took 4.524033784866333 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.9768723 | 1.941643 - batch took 4.531174659729004 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.8377056 | 1.581079 - batch took 4.5392069816589355 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.8565222 | 2.0674756 - batch took 4.509603261947632 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.2054992 | 1.6593388 - batch took 4.527544975280762 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.0515761 | 2.3468785 - batch took 4.5158913135528564 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.0078726 | 1.6364586 - batch took 4.51894998550415 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.4589045 | 2.0724504 - batch took 4.521677494049072 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.6763604 | 2.2481089 - batch took 4.548353910446167 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.9833751 | 1.27026 - batch took 4.58613133430481 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.7591268 | 2.051063 - batch took 4.566386699676514 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.0797412 | 1.512201 - batch took 4.537437200546265 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.4979231 | 1.6587349 - batch took 4.519010782241821 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.0782154 | 3.167007 - batch took 4.548115968704224 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.1369696 | 2.0797267 - batch took 4.526109933853149 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.0139372 | 2.0361538 - batch took 4.533134460449219 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.0582619 | 1.8799028 - batch took 4.531348466873169 s.\n",
            "Epoch 22/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.8387082 | 1.8805745 - batch took 4.513633966445923 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.5850543 | 2.0961225 - batch took 4.526449680328369 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.099017 | 1.9836103 - batch took 4.520414352416992 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.8875113 | 1.7136345 - batch took 4.521766424179077 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.5951189 | 1.7937304 - batch took 4.526657819747925 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.8420186 | 1.6079874 - batch took 4.506318807601929 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.9519138 | 1.8674527 - batch took 4.533632278442383 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.8009226 | 1.9138529 - batch took 4.523132562637329 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.8089154 | 2.0636244 - batch took 4.539875268936157 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.1994693 | 1.9197271 - batch took 4.5259435176849365 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.885499 | 1.5308218 - batch took 4.534755706787109 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.1934347 | 1.8352101 - batch took 4.5299072265625 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.9146855 | 2.408052 - batch took 4.507289409637451 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.1135662 | 2.228892 - batch took 4.521593332290649 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.146792 | 2.3588586 - batch took 4.517477512359619 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.3089075 | 2.1966228 - batch took 4.515272617340088 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.2032957 | 2.4387302 - batch took 4.528847694396973 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.6973102 | 1.5296804 - batch took 4.514447927474976 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.4631438 | 1.3702548 - batch took 4.527610778808594 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.7550576 | 1.8102514 - batch took 4.538935422897339 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.0696445 | 1.4115238 - batch took 3.484236240386963 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.1547816 | 1.9967563 - batch took 4.551493883132935 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.0749288 | 1.5546176 - batch took 4.511958837509155 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.8435473 | 1.55778 - batch took 4.542032241821289 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.0431528 | 1.1533722 - batch took 4.512374401092529 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.6131849 | 1.7699783 - batch took 4.552967548370361 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.188549 | 1.7913141 - batch took 4.547444105148315 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.6717553 | 2.4791925 - batch took 4.511003017425537 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.8944044 | 2.217208 - batch took 4.483327150344849 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.9690132 | 1.8709121 - batch took 4.517651557922363 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.016465 | 1.650468 - batch took 4.5303661823272705 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.9949708 | 1.8422415 - batch took 4.539548635482788 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.25125 | 1.2311819 - batch took 4.522135257720947 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.4762466 | 1.2221228 - batch took 4.5217063426971436 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.9893768 | 2.0146778 - batch took 4.514842748641968 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.0278473 | 1.7200282 - batch took 4.523171663284302 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.2154622 | 1.8496696 - batch took 4.525327920913696 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.8907466 | 1.6221656 - batch took 4.520169496536255 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.782652 | 1.8355634 - batch took 4.520361661911011 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.628962 | 1.7910078 - batch took 4.529979705810547 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.9531642 | 2.0970302 - batch took 4.515161037445068 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.6380513 | 1.8121493 - batch took 4.534550428390503 s.\n",
            "Epoch 23/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.7244502 | 1.9427547 - batch took 4.538005590438843 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 2.0348363 | 1.8384919 - batch took 4.528877258300781 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 1.7516484 | 1.7273053 - batch took 4.523675203323364 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.1114545 | 1.8251582 - batch took 4.533669710159302 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.5734321 | 1.4400483 - batch took 4.519106388092041 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.150856 | 1.8368955 - batch took 4.513643980026245 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.5085119 | 1.6757851 - batch took 4.509361505508423 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.4561272 | 1.924801 - batch took 4.523787975311279 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.2309322 | 2.094709 - batch took 4.5124475955963135 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.1576529 | 1.9294875 - batch took 4.521146774291992 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.4982866 | 1.7702136 - batch took 4.516592741012573 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.8726068 | 1.5559251 - batch took 4.539085626602173 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.7242837 | 1.5183197 - batch took 4.53214168548584 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.8773596 | 1.5043402 - batch took 4.533432483673096 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.386274 | 2.4044595 - batch took 4.517674922943115 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 1.6106731 | 1.6664929 - batch took 4.530165195465088 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.3903027 | 1.6076702 - batch took 4.5187156200408936 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.967561 | 2.005087 - batch took 4.5196356773376465 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 1.8311523 | 2.068299 - batch took 4.510003566741943 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.6083481 | 1.3323001 - batch took 4.5451743602752686 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.5841115 | 2.3217325 - batch took 4.539236545562744 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.6180367 | 1.2686193 - batch took 3.5012974739074707 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.108685 | 2.2825246 - batch took 4.534473180770874 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.8932511 | 1.865744 - batch took 4.545567512512207 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.8762614 | 1.2787695 - batch took 4.505786657333374 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.6705921 | 1.6414826 - batch took 4.524092197418213 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.7859784 | 1.5907863 - batch took 4.538421154022217 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.4625497 | 1.2960823 - batch took 4.508508682250977 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.437552 | 2.419501 - batch took 4.519550800323486 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.8493094 | 1.5712655 - batch took 4.517561912536621 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.3147705 | 2.183579 - batch took 4.513845682144165 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.956942 | 1.8292122 - batch took 4.533874273300171 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.67127 | 2.0358877 - batch took 4.5177178382873535 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.843991 | 2.12327 - batch took 4.53656268119812 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.8866249 | 1.8625658 - batch took 4.527105331420898 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.0894501 | 2.0363114 - batch took 4.524659872055054 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.1608803 | 1.7631216 - batch took 4.513166427612305 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.6395606 | 1.4803898 - batch took 4.51788067817688 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.0781274 | 1.525852 - batch took 4.5319695472717285 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.4710665 | 2.16076 - batch took 4.527052640914917 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.7902224 | 2.1737432 - batch took 4.518949747085571 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.804862 | 1.8197227 - batch took 4.515194654464722 s.\n",
            "Epoch 24/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.7576425 | 1.3206186 - batch took 4.529002666473389 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.774831 | 1.91911 - batch took 4.5430896282196045 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.1191783 | 1.5192007 - batch took 4.526151895523071 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.5437376 | 1.5840938 - batch took 4.51518988609314 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.1210804 | 2.0783472 - batch took 4.527477025985718 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.090479 | 1.8301282 - batch took 4.514915227890015 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.7273412 | 1.6486928 - batch took 4.520899534225464 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.8606328 | 1.5489146 - batch took 4.522130489349365 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.12608 | 1.6364399 - batch took 4.53794002532959 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 1.5945632 | 1.3251584 - batch took 4.53118109703064 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.4308293 | 1.6423776 - batch took 4.503413438796997 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.0656478 | 2.2482495 - batch took 4.511489391326904 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.7964883 | 1.7871344 - batch took 4.523865222930908 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.8873568 | 1.6972492 - batch took 4.535139560699463 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.8135364 | 2.1006837 - batch took 4.516319274902344 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.350709 | 1.3709699 - batch took 4.53173303604126 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.8843763 | 1.6315231 - batch took 4.5334484577178955 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.3600874 | 1.8222554 - batch took 4.518802642822266 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2999973 | 2.3947792 - batch took 4.5378148555755615 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9280632 | 2.0289059 - batch took 4.517087936401367 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.0572968 | 2.1675205 - batch took 4.521780014038086 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 1.5753341 | 2.652381 - batch took 4.512994289398193 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.3769438 | 1.5158062 - batch took 3.4945547580718994 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.2609181 | 2.2176447 - batch took 4.525683879852295 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.8856066 | 2.3814292 - batch took 4.524734020233154 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.8467234 | 1.4614747 - batch took 4.5211098194122314 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.3412917 | 1.4732769 - batch took 4.51284384727478 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3627381 | 2.5465813 - batch took 4.51517391204834 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.2460222 | 2.268876 - batch took 4.541528940200806 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.4617536 | 1.8929152 - batch took 4.5313475131988525 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.3353784 | 1.8198023 - batch took 4.519920349121094 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.9767984 | 1.5562663 - batch took 4.520181655883789 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.6744261 | 1.7836591 - batch took 4.52938175201416 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.0584242 | 1.4707915 - batch took 4.529199838638306 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.1664276 | 2.0210102 - batch took 4.527112722396851 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.0707355 | 1.6262313 - batch took 4.5136027336120605 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.409716 | 1.6418813 - batch took 4.5243048667907715 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.10259 | 1.9701782 - batch took 4.509819030761719 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.653228 | 1.5950093 - batch took 4.518437147140503 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.2670784 | 1.4719818 - batch took 4.512882232666016 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.035225 | 1.9800519 - batch took 4.546758413314819 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.7845778 | 1.8102398 - batch took 4.534075498580933 s.\n",
            "Epoch 25/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.329937 | 2.0023386 - batch took 4.528716802597046 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.7070082 | 1.6613195 - batch took 4.526491641998291 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 1.6838368 | 1.896512 - batch took 4.529217720031738 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.082364 | 1.527258 - batch took 4.512798547744751 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.0056524 | 2.046449 - batch took 4.543750286102295 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.7936026 | 1.6904844 - batch took 4.53963041305542 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.6622934 | 2.0123656 - batch took 4.515809774398804 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.6081183 | 2.0520144 - batch took 4.517059803009033 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.8997192 | 1.7000309 - batch took 4.531844854354858 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.14647 | 1.8039128 - batch took 4.507010221481323 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.4095385 | 2.4472313 - batch took 4.525145053863525 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.2352204 | 1.5342104 - batch took 4.521891832351685 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.81572 | 1.8300877 - batch took 4.520852565765381 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.8238822 | 1.3877661 - batch took 4.517131090164185 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.7796388 | 1.7474133 - batch took 4.523643732070923 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.274879 | 1.1327686 - batch took 4.539481163024902 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.1471467 | 1.8628502 - batch took 4.513407230377197 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.6964463 | 1.6580312 - batch took 4.522930383682251 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.4603417 | 1.9336971 - batch took 4.522531032562256 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9108355 | 1.7213607 - batch took 4.528628826141357 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.9919479 | 1.5396874 - batch took 4.538465738296509 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.3739765 | 2.4210267 - batch took 4.513481616973877 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.2645116 | 1.8030622 - batch took 4.521705865859985 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.5552979 | 1.456487 - batch took 3.512911796569824 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.2991247 | 1.7535443 - batch took 4.523345232009888 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 1.7716608 | 1.8570004 - batch took 4.529897689819336 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.83118 | 1.414428 - batch took 4.5144312381744385 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.0162442 | 1.9176097 - batch took 4.522912979125977 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.8513339 | 1.4886237 - batch took 4.517580270767212 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.7212718 | 1.753917 - batch took 4.5139617919921875 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.5124412 | 1.305331 - batch took 4.5224809646606445 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 1.6990128 | 1.7965966 - batch took 4.519798994064331 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.1037292 | 1.5242019 - batch took 4.539377450942993 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.9264504 | 1.4349593 - batch took 4.5271172523498535 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.3444836 | 1.6401212 - batch took 4.530519485473633 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.892772 | 1.605742 - batch took 4.541141510009766 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.135036 | 1.7715707 - batch took 4.520288467407227 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.325468 | 1.647362 - batch took 4.5119948387146 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.7615948 | 1.9685975 - batch took 4.5099570751190186 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.1673837 | 2.0365949 - batch took 4.520270347595215 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.0224712 | 1.6993611 - batch took 4.514254331588745 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.9198978 | 1.2209611 - batch took 4.5233564376831055 s.\n",
            "Epoch 26/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.5868483 | 1.4652722 - batch took 4.540513277053833 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.6592072 | 1.336211 - batch took 4.5392677783966064 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.844008 | 1.4634023 - batch took 4.531752109527588 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.3023293 | 2.334813 - batch took 4.517068147659302 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.7863604 | 2.661016 - batch took 4.5430006980896 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.9696347 | 2.2742105 - batch took 4.51473069190979 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.6986532 | 2.256813 - batch took 4.512957811355591 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.122633 | 1.2638377 - batch took 4.5223023891448975 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.6797811 | 1.4610248 - batch took 4.51296067237854 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.1183248 | 1.0268235 - batch took 4.52379035949707 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.6968842 | 2.363523 - batch took 4.505364894866943 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.9761817 | 2.3945968 - batch took 4.526455402374268 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.4748468 | 1.9111679 - batch took 4.530158758163452 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.9034629 | 1.9063599 - batch took 4.534839391708374 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.0663967 | 1.7314069 - batch took 4.534688472747803 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.5168328 | 2.204307 - batch took 4.521793842315674 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.5172755 | 1.748738 - batch took 4.529516935348511 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.9219611 | 1.7290727 - batch took 4.529165029525757 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.2948108 | 1.8924043 - batch took 4.511632442474365 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9924393 | 1.677079 - batch took 4.528397798538208 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 1.7381918 | 1.4379734 - batch took 4.520055294036865 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.3380747 | 1.9794536 - batch took 4.507422685623169 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.5076854 | 2.0857866 - batch took 4.5252604484558105 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.1441898 | 1.4069498 - batch took 4.528776407241821 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.933115 | 2.0524073 - batch took 3.4855339527130127 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.0647588 | 1.5556664 - batch took 4.543458461761475 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.2686253 | 1.8959683 - batch took 4.534272193908691 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.9486003 | 1.6894643 - batch took 4.528073310852051 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.1442695 | 1.5279679 - batch took 4.534980058670044 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.8267794 | 1.633435 - batch took 4.5275468826293945 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.0058846 | 1.2580551 - batch took 4.505573749542236 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.2301495 | 1.824698 - batch took 4.548507452011108 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.2506135 | 1.5741243 - batch took 4.536722183227539 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.7695429 | 1.4245007 - batch took 4.525395154953003 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.3345373 | 1.617611 - batch took 4.501040697097778 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.89174 | 1.5863085 - batch took 4.525059938430786 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.8183868 | 1.2985183 - batch took 4.528704643249512 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 1.9810038 | 1.8498867 - batch took 4.513987302780151 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.1645117 | 1.987082 - batch took 4.5164954662323 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.9273031 | 1.4775791 - batch took 4.532656192779541 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.3068013 | 1.983101 - batch took 4.5257203578948975 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.5971751 | 1.3879621 - batch took 4.524467706680298 s.\n",
            "Epoch 27/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.0940783 | 1.8129547 - batch took 4.511218070983887 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.838146 | 1.5102674 - batch took 4.527404069900513 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.1534681 | 1.7695665 - batch took 4.528628826141357 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 1.8650112 | 1.5402433 - batch took 4.506669044494629 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.4588814 | 1.455437 - batch took 4.530377149581909 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.4933858 | 2.5975895 - batch took 4.534301519393921 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 1.7556143 | 1.9804536 - batch took 4.525090932846069 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.39975 | 1.3394084 - batch took 4.5216076374053955 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.7339399 | 2.2970586 - batch took 4.512442111968994 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.002659 | 1.3427231 - batch took 4.53881573677063 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.294881 | 1.5114055 - batch took 4.523235082626343 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.6491394 | 2.0847273 - batch took 4.521173477172852 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.378039 | 2.2545033 - batch took 4.514270544052124 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 2.7599926 | 1.8144674 - batch took 4.517712593078613 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.1931746 | 2.3824015 - batch took 4.525165319442749 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.110625 | 1.8422291 - batch took 4.552037239074707 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.9446852 | 1.68924 - batch took 4.527483701705933 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.27488 | 1.745759 - batch took 4.535526514053345 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.171867 | 2.4236512 - batch took 4.5036633014678955 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.9165742 | 1.4547626 - batch took 4.605911016464233 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.1727028 | 1.39179 - batch took 4.532824277877808 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.3006067 | 1.8739536 - batch took 4.550621747970581 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 1.5846524 | 1.6106803 - batch took 4.536048889160156 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.626624 | 1.2466903 - batch took 4.533387899398804 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.645611 | 1.7226286 - batch took 4.532056093215942 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.6133428 | 2.5399933 - batch took 3.507843017578125 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.0722842 | 1.7801965 - batch took 4.537472486495972 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.634059 | 2.0110736 - batch took 4.51868462562561 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.1762915 | 1.9659574 - batch took 4.539809465408325 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 2.8760056 | 1.8405088 - batch took 4.51727032661438 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.5239947 | 2.1296978 - batch took 4.521024465560913 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.087924 | 2.1273575 - batch took 4.533668279647827 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.459256 | 1.717235 - batch took 4.5297324657440186 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 1.5846064 | 2.046874 - batch took 4.52286958694458 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.1787183 | 1.4395311 - batch took 4.52107048034668 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.1319513 | 1.5930877 - batch took 4.534346342086792 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 1.4128488 | 1.4538494 - batch took 4.519713640213013 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.302291 | 1.4754375 - batch took 4.515113592147827 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.8703507 | 1.4996314 - batch took 4.518557548522949 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 1.7986637 | 1.4643984 - batch took 4.514438152313232 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.0669746 | 1.7237487 - batch took 4.512600660324097 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 1.9366469 | 1.5637647 - batch took 4.513978481292725 s.\n",
            "Epoch 28/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.8996463 | 1.681236 - batch took 4.525390148162842 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.980284 | 1.7031578 - batch took 4.548718452453613 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.1994624 | 2.0197866 - batch took 4.532132625579834 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.1645496 | 1.3301487 - batch took 4.529785633087158 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.5483254 | 2.0310688 - batch took 4.526185512542725 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.1415982 | 1.9554029 - batch took 4.524602890014648 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.0635881 | 2.6692123 - batch took 4.517364740371704 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.5934786 | 1.2317181 - batch took 4.5173516273498535 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.870429 | 1.4709921 - batch took 4.517223834991455 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.3761487 | 1.5756314 - batch took 4.515746593475342 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.8269644 | 1.6662629 - batch took 4.517050266265869 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 1.827462 | 1.10554 - batch took 4.511666774749756 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.7792642 | 1.8900652 - batch took 4.530832290649414 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.8260185 | 1.8341167 - batch took 4.539989709854126 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.8017228 | 1.7066343 - batch took 4.527570962905884 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.0402892 | 2.2552743 - batch took 4.519919395446777 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.157946 | 1.6805825 - batch took 4.556291818618774 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 1.7654376 | 1.7992036 - batch took 4.577794790267944 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.105198 | 1.518784 - batch took 4.5416786670684814 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.0573182 | 1.7486773 - batch took 4.52545428276062 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.1965504 | 1.6512552 - batch took 4.549005746841431 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.6156874 | 1.8020592 - batch took 4.532857894897461 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.0245948 | 1.6773252 - batch took 4.515337944030762 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.8601503 | 1.052813 - batch took 4.521536111831665 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.1737876 | 2.095046 - batch took 4.5442280769348145 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.3181803 | 1.1667607 - batch took 4.526965618133545 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.1703784 | 2.8575017 - batch took 3.511009454727173 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.0902877 | 1.6770822 - batch took 4.530103921890259 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.204898 | 1.5769156 - batch took 4.535431861877441 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.9988286 | 1.6854905 - batch took 4.527145862579346 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.9564604 | 1.36438 - batch took 4.5335540771484375 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.9817138 | 1.7241877 - batch took 4.515506744384766 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 1.5084668 | 1.758628 - batch took 4.538083791732788 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.132144 | 1.6518159 - batch took 4.515697956085205 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.9855636 | 1.9037503 - batch took 4.52816367149353 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.909733 | 1.6502333 - batch took 4.51206111907959 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 1.9711843 | 1.3369713 - batch took 4.524073362350464 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.0970156 | 1.6313306 - batch took 4.526043653488159 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.2564769 | 1.3804586 - batch took 4.513748407363892 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.7904236 | 2.0320873 - batch took 4.5340306758880615 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.871832 | 1.438584 - batch took 4.53344988822937 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.556367 | 2.179812 - batch took 4.5271241664886475 s.\n",
            "Epoch 29/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 1.883693 | 1.7383246 - batch took 4.538987636566162 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.9243246 | 2.1135907 - batch took 4.50279688835144 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 2.0316694 | 1.690515 - batch took 4.528212308883667 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 2.413794 | 1.8403426 - batch took 4.536959648132324 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 1.7075131 | 1.390831 - batch took 4.502044677734375 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 1.8204644 | 1.3665917 - batch took 4.529953718185425 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.2610471 | 1.5884689 - batch took 4.517060995101929 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 1.7791662 | 1.2463996 - batch took 4.502124309539795 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 1.9108906 | 1.5579869 - batch took 4.524761915206909 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.0969644 | 1.3769907 - batch took 4.528266429901123 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 2.3026366 | 1.5515717 - batch took 4.539347171783447 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.4737494 | 1.7829595 - batch took 4.52898907661438 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 2.3666315 | 2.3279588 - batch took 4.535460948944092 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.9111891 | 1.4663789 - batch took 4.516098499298096 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 1.7838085 | 1.3430846 - batch took 4.529910087585449 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.2210526 | 1.338445 - batch took 4.512480735778809 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 2.042439 | 1.2504878 - batch took 4.521516561508179 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.3023071 | 1.6890719 - batch took 4.532613039016724 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.1834857 | 1.9624143 - batch took 4.519723415374756 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 1.4802506 | 1.651061 - batch took 4.5322980880737305 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.0137234 | 1.6662738 - batch took 4.527430295944214 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.0612376 | 1.2577722 - batch took 4.517516851425171 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.0250657 | 2.1161532 - batch took 4.526328802108765 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 1.9706168 | 1.3438946 - batch took 4.510973691940308 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 1.6958634 | 1.4713047 - batch took 4.530943155288696 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.1271424 | 1.1839837 - batch took 4.522274494171143 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 2.053578 | 1.6583247 - batch took 4.525311231613159 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 1.7658378 | 1.681417 - batch took 3.5073652267456055 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 1.9981194 | 1.3372058 - batch took 4.519541501998901 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.9399493 | 1.5937968 - batch took 4.515073299407959 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 2.1747785 | 1.2891793 - batch took 4.5149219036102295 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 2.1349154 | 1.674406 - batch took 4.52570915222168 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.1644697 | 1.414861 - batch took 4.544133186340332 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.1501822 | 1.7199175 - batch took 4.528746843338013 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 2.4662423 | 1.8064842 - batch took 4.5259528160095215 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 1.8630445 | 2.41989 - batch took 4.525960922241211 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 2.600472 | 1.4787314 - batch took 4.528095245361328 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.2299604 | 1.6171687 - batch took 4.526277542114258 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 1.9754102 | 1.622266 - batch took 4.5149312019348145 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.527666 | 1.1610165 - batch took 4.527814865112305 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 1.8127702 | 1.7170093 - batch took 4.521629333496094 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.1109273 | 1.6807086 - batch took 4.516729116439819 s.\n",
            "Epoch 30/30 :\n",
            "     Batch 1/42 generator loss | discriminator loss : 2.3378992 | 1.3179624 - batch took 4.5414862632751465 s.\n",
            "     Batch 2/42 generator loss | discriminator loss : 1.9103825 | 1.6822538 - batch took 4.566711902618408 s.\n",
            "     Batch 3/42 generator loss | discriminator loss : 1.861216 | 1.4728997 - batch took 4.576458215713501 s.\n",
            "     Batch 4/42 generator loss | discriminator loss : 3.1405559 | 1.816952 - batch took 4.524398326873779 s.\n",
            "     Batch 5/42 generator loss | discriminator loss : 2.0339155 | 1.9516165 - batch took 4.528995513916016 s.\n",
            "     Batch 6/42 generator loss | discriminator loss : 2.2333798 | 1.4598086 - batch took 4.534358263015747 s.\n",
            "     Batch 7/42 generator loss | discriminator loss : 2.1697145 | 1.7956312 - batch took 4.522281885147095 s.\n",
            "     Batch 8/42 generator loss | discriminator loss : 2.4551067 | 1.6206312 - batch took 4.543771266937256 s.\n",
            "     Batch 9/42 generator loss | discriminator loss : 2.1264906 | 2.2413938 - batch took 4.531664133071899 s.\n",
            "     Batch 10/42 generator loss | discriminator loss : 2.1231961 | 1.2029737 - batch took 4.540327072143555 s.\n",
            "     Batch 11/42 generator loss | discriminator loss : 1.7822106 | 1.8586034 - batch took 4.527272462844849 s.\n",
            "     Batch 12/42 generator loss | discriminator loss : 2.5075712 | 1.8336046 - batch took 4.5228376388549805 s.\n",
            "     Batch 13/42 generator loss | discriminator loss : 1.9247453 | 2.0955284 - batch took 4.53078818321228 s.\n",
            "     Batch 14/42 generator loss | discriminator loss : 1.9741981 | 1.5860747 - batch took 4.509793281555176 s.\n",
            "     Batch 15/42 generator loss | discriminator loss : 2.3201537 | 1.4064747 - batch took 4.532607555389404 s.\n",
            "     Batch 16/42 generator loss | discriminator loss : 2.5884168 | 1.629065 - batch took 4.520098924636841 s.\n",
            "     Batch 17/42 generator loss | discriminator loss : 1.8358966 | 1.6987767 - batch took 4.521953344345093 s.\n",
            "     Batch 18/42 generator loss | discriminator loss : 2.858059 | 1.1057075 - batch took 4.526078701019287 s.\n",
            "     Batch 19/42 generator loss | discriminator loss : 2.4705687 | 1.8773812 - batch took 4.527657747268677 s.\n",
            "     Batch 20/42 generator loss | discriminator loss : 2.4627087 | 1.5655296 - batch took 4.525133848190308 s.\n",
            "     Batch 21/42 generator loss | discriminator loss : 2.1141348 | 1.7432427 - batch took 4.5160839557647705 s.\n",
            "     Batch 22/42 generator loss | discriminator loss : 2.4093215 | 1.072979 - batch took 4.523381233215332 s.\n",
            "     Batch 23/42 generator loss | discriminator loss : 2.3583078 | 1.8098159 - batch took 4.526001691818237 s.\n",
            "     Batch 24/42 generator loss | discriminator loss : 2.0640533 | 1.5866373 - batch took 4.527853488922119 s.\n",
            "     Batch 25/42 generator loss | discriminator loss : 2.7343051 | 1.5425863 - batch took 4.52593731880188 s.\n",
            "     Batch 26/42 generator loss | discriminator loss : 2.1585932 | 1.8718113 - batch took 4.512903451919556 s.\n",
            "     Batch 27/42 generator loss | discriminator loss : 1.9262037 | 1.1422642 - batch took 4.5045154094696045 s.\n",
            "     Batch 28/42 generator loss | discriminator loss : 2.3034723 | 1.5854671 - batch took 4.531914472579956 s.\n",
            "     Batch 29/42 generator loss | discriminator loss : 2.1118197 | 1.5197723 - batch took 3.499178409576416 s.\n",
            "     Batch 30/42 generator loss | discriminator loss : 1.9365875 | 1.4660983 - batch took 4.564277172088623 s.\n",
            "     Batch 31/42 generator loss | discriminator loss : 1.4109697 | 1.1582525 - batch took 4.527386665344238 s.\n",
            "     Batch 32/42 generator loss | discriminator loss : 3.0282342 | 1.4972306 - batch took 4.53291654586792 s.\n",
            "     Batch 33/42 generator loss | discriminator loss : 2.532073 | 2.1121483 - batch took 4.514112234115601 s.\n",
            "     Batch 34/42 generator loss | discriminator loss : 2.3998582 | 1.5562587 - batch took 4.524847745895386 s.\n",
            "     Batch 35/42 generator loss | discriminator loss : 1.9881577 | 1.4398191 - batch took 4.518331527709961 s.\n",
            "     Batch 36/42 generator loss | discriminator loss : 2.528987 | 1.4224544 - batch took 4.521081924438477 s.\n",
            "     Batch 37/42 generator loss | discriminator loss : 3.0801544 | 2.3178992 - batch took 4.521695137023926 s.\n",
            "     Batch 38/42 generator loss | discriminator loss : 2.2107592 | 1.8525136 - batch took 4.524844408035278 s.\n",
            "     Batch 39/42 generator loss | discriminator loss : 2.6722932 | 1.7153032 - batch took 4.51096248626709 s.\n",
            "     Batch 40/42 generator loss | discriminator loss : 2.3978467 | 1.8406905 - batch took 4.535198450088501 s.\n",
            "     Batch 41/42 generator loss | discriminator loss : 2.4128442 | 2.131987 - batch took 4.521468639373779 s.\n",
            "     Batch 42/42 generator loss | discriminator loss : 2.260887 | 1.0865822 - batch took 4.537529468536377 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwMKyPex5Nag",
        "colab_type": "code",
        "outputId": "154c46c2-156e-4af0-f6be-a2dd62c9f0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Sneakers/sneaker-generator-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPJH9QTVSNVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdwrYIIH2qQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "def construct_generator():\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(units=16 * 16 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(16, 16, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=None)\n",
        "\n",
        "    return generator\n",
        "\n",
        "def predict():\n",
        "    generator = construct_generator()\n",
        "\n",
        "    if os.path.exists(\"./output/generator_weights.h5\"):\n",
        "        print('loaded generator model weights')\n",
        "        generator.load_weights('./output/generator_weights.h5')\n",
        "\n",
        "    # Saving model for tensorflow.js\n",
        "    tfjs.converters.save_keras_model(generator, 'generator')\n",
        "\n",
        "    batch_size = 64\n",
        "\n",
        "    # Generate noise\n",
        "    noise = np.random.uniform(size=[batch_size, 1, 1, 100])\n",
        "    print(noise.shape)\n",
        "\n",
        "    # Generate images\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    # Save images\n",
        "    for i in range(batch_size):\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        matplotlib.image.imsave('./output/shoe%d.png' % i, image.astype(np.uint8))\n",
        "\n",
        "predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKi9BAW9Ck1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}